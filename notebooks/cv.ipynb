{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covid-19 X-ray predictor\n",
    "========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "pd.options.display.max_colwidth = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_found(path: str) -> bool:\n",
    "    return not os.path.exists(path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"..\"\n",
    "data_path = os.path.join(base, \"data\")\n",
    "metadata = pd.read_csv(os.path.join(data_path, \"metadata.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finding</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/auntminnie-b-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/auntminnie-c-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/auntminnie-d-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/nejmc2001573_f1a.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/figure1-5e75d0940b71e1b702629659-98-right.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/figure1-5e71be566aa8714a04de3386-98-left.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/2966893D-5DDF-4B68-9E2B-4979D5956C8E.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/B2D20576-00B7-4519-A415-72DE29C90C34.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>/data/sources/covid-19-cv/data/PA/COVID-19/6C94A287-C059-46A0-8600-AFB95F4727B7.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      finding  \\\n",
       "0    COVID-19   \n",
       "1    COVID-19   \n",
       "2    COVID-19   \n",
       "3    COVID-19   \n",
       "4    COVID-19   \n",
       "..        ...   \n",
       "150  COVID-19   \n",
       "151  COVID-19   \n",
       "155  COVID-19   \n",
       "156  COVID-19   \n",
       "157  COVID-19   \n",
       "\n",
       "                                                                                                                  path  \n",
       "0    /data/sources/covid-19-cv/data/PA/COVID-19/auntminnie-a-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg  \n",
       "1    /data/sources/covid-19-cv/data/PA/COVID-19/auntminnie-b-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg  \n",
       "2    /data/sources/covid-19-cv/data/PA/COVID-19/auntminnie-c-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg  \n",
       "3    /data/sources/covid-19-cv/data/PA/COVID-19/auntminnie-d-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg  \n",
       "4                                                     /data/sources/covid-19-cv/data/PA/COVID-19/nejmc2001573_f1a.jpeg  \n",
       "..                                                                                                                 ...  \n",
       "150                          /data/sources/covid-19-cv/data/PA/COVID-19/figure1-5e75d0940b71e1b702629659-98-right.jpeg  \n",
       "151                           /data/sources/covid-19-cv/data/PA/COVID-19/figure1-5e71be566aa8714a04de3386-98-left.jpeg  \n",
       "155                               /data/sources/covid-19-cv/data/PA/COVID-19/2966893D-5DDF-4B68-9E2B-4979D5956C8E.jpeg  \n",
       "156                               /data/sources/covid-19-cv/data/PA/COVID-19/B2D20576-00B7-4519-A415-72DE29C90C34.jpeg  \n",
       "157                               /data/sources/covid-19-cv/data/PA/COVID-19/6C94A287-C059-46A0-8600-AFB95F4727B7.jpeg  \n",
       "\n",
       "[99 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa = metadata.where((metadata.view == \"PA\") & (metadata.modality == \"X-ray\"))[[\"finding\", \"path\"]].dropna()\n",
    "print(pa.shape)\n",
    "pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path: str):\n",
    "    image = cv2.imread(image_path)\n",
    "    return cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (224, 224))\n",
    "\n",
    "def image_loader(row):\n",
    "    if(not_found(row[\"path\"])):\n",
    "       print(\"NOT FOUND\")\n",
    "    return get_image(row[\"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 4)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa[\"image\"] = pa.apply(image_loader, axis=1)\n",
    "pa[\"label\"] = pa.apply(lambda row: \"COVID-19\" if row[\"finding\"]==\"COVID-19\" else \"other\", axis=1)\n",
    "pa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbs = pa[\"label\"].to_numpy()\n",
    "lbs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Preparing the model\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = to_categorical(lb.fit_transform(lbs))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 224, 224, 3)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  np.array(pa[\"image\"].to_list()) / 255.0 #scale intensities to the range [0, 255]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.2, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3 #learning rate\n",
    "EPOCHS = 25 \n",
    "BS = 8 #batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trotation_range=15,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(64, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR)#, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "WARNING:tensorflow:From <ipython-input-187-1ae9c595fffb>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 9 steps, validate on 20 samples\n",
      "Epoch 1/25\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.6731 - accuracy: 0.6620 - val_loss: 0.5751 - val_accuracy: 0.6875\n",
      "Epoch 2/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6514 - accuracy: 0.7500 - val_loss: 0.4937 - val_accuracy: 0.6875\n",
      "Epoch 3/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.5415 - accuracy: 0.7606 - val_loss: 0.4714 - val_accuracy: 0.6875\n",
      "Epoch 4/25\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.5170 - accuracy: 0.7746 - val_loss: 0.4811 - val_accuracy: 0.6875\n",
      "Epoch 5/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.5262 - accuracy: 0.8028 - val_loss: 0.4777 - val_accuracy: 0.6875\n",
      "Epoch 6/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.5442 - accuracy: 0.7606 - val_loss: 0.4344 - val_accuracy: 0.6875\n",
      "Epoch 7/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.4410 - accuracy: 0.8028 - val_loss: 0.4200 - val_accuracy: 0.6875\n",
      "Epoch 8/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.5109 - accuracy: 0.7887 - val_loss: 0.4395 - val_accuracy: 0.6875\n",
      "Epoch 9/25\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.5448 - accuracy: 0.7465 - val_loss: 0.4490 - val_accuracy: 0.6875\n",
      "Epoch 10/25\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.5254 - accuracy: 0.7500 - val_loss: 0.4196 - val_accuracy: 0.6875\n",
      "Epoch 11/25\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.5064 - accuracy: 0.7465 - val_loss: 0.4120 - val_accuracy: 0.6875\n",
      "Epoch 12/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.5106 - accuracy: 0.7746 - val_loss: 0.4009 - val_accuracy: 0.6875\n",
      "Epoch 13/25\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4249 - accuracy: 0.7887 - val_loss: 0.3847 - val_accuracy: 0.6875\n",
      "Epoch 14/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.4490 - accuracy: 0.7746 - val_loss: 0.4254 - val_accuracy: 0.6875\n",
      "Epoch 15/25\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4660 - accuracy: 0.7746 - val_loss: 0.4236 - val_accuracy: 0.6875\n",
      "Epoch 16/25\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.4800 - accuracy: 0.8169 - val_loss: 0.3648 - val_accuracy: 0.6875\n",
      "Epoch 17/25\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4511 - accuracy: 0.8194 - val_loss: 0.3536 - val_accuracy: 0.6875\n",
      "Epoch 18/25\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.4748 - accuracy: 0.7746 - val_loss: 0.3483 - val_accuracy: 0.6875\n",
      "Epoch 19/25\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.5163 - accuracy: 0.7500 - val_loss: 0.3511 - val_accuracy: 0.6875\n",
      "Epoch 20/25\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.4956 - accuracy: 0.8028 - val_loss: 0.3679 - val_accuracy: 0.6875\n",
      "Epoch 21/25\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.4697 - accuracy: 0.7887 - val_loss: 0.3624 - val_accuracy: 0.6875\n",
      "Epoch 22/25\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4591 - accuracy: 0.7324 - val_loss: 0.3513 - val_accuracy: 0.6875\n",
      "Epoch 23/25\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4468 - accuracy: 0.8451 - val_loss: 0.3478 - val_accuracy: 0.6875\n",
      "Epoch 24/25\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3676 - accuracy: 0.8451 - val_loss: 0.3723 - val_accuracy: 0.6875\n",
      "Epoch 25/25\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.5154 - accuracy: 0.7917 - val_loss: 0.3661 - val_accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\ttrainAug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}